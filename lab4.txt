getwd()
setwd('R/x86_64-pc-linux-gnu-library/3.4/codes/week4')
getwd()


salary=read.table("salary.txt", sep="", header=F)
plot(salary)
salary
names(salary)[1]<-paste("year")
names(salary)[2]<-paste("dollar")
header(salary)
head(salary)



fit1= lm(dollar~1+I(year^2), data=salary); fit1
summary(fit1)

#2.b test if the slope is 0
#the p value for that is 2*10^-14 which is small, therefore reject the null hy;pothesis

#2.c test if intercept is 0
#p value for that is 2e-16 so reject

#2.d
#estimate for sigma^2 is ('residual standard error')^2
sigma_hat_sq=fit1.su$'Residual standard error'
sigma_hat_sq=summary(fit1)$'Residual standard error'
sigma_hat_sq
#read out from table
#take the square of that

#2.e comment on the total variation explained by the modell
summary(fit1)
#we see that r^2 = 0.8182 hence 81% of the data are explained by our modell

#2.f is the modell useful to predict salaries, 5% sig level
anova(fit1)
# he uses a different value for the F value, so dont know whats going on but our F value is small (2.2e-16 ) so the modell is useful to predict sallaries. he also said that the F stat shows whether our model is better with the slope parameter or without
#sometimes he uses the value from the table, sometimes a different value
 
#2.g predict a salary for 20 years, with a 95% prediction interval 
newexp = data.frame(year=20)
exper20=predict(fit1,newdata=newexp, interval = 'prediction') ; exper20
#so the predicted salary is 51 with a 95% prediction interval (34.6,67.57)

#2.h
#if the regression modell is correct, the variance of the residuals should not depend on the values of the predictor
#i. plot the residuals vs fitted values
plot(fitted(fit1), residuals(fit1))
plot(salary$year^2, residuals(fit1))
# if the variance grows than we have a wrong modell
#variance of residuals depends on the predictor variables meaning for different xi we have a different region of variance. this  a contradiction, modell is shite
savehistory('lab4.txt')

getwd()
setwd('R/x86_64-pc-linux-gnu-library/3.4/codes/week4')
getwd()


salary=read.table("salary.txt", sep="", header=F)
plot(salary)
salary
names(salary)[1]<-paste("year")
names(salary)[2]<-paste("dollar")
header(salary)
head(salary)



fit1= lm(dollar~1+I(year^2), data=salary); fit1
summary(fit1)

#2.b test if the slope is 0
#the p value for that is 2*10^-14 which is small, therefore reject the null hy;pothesis

#2.c test if intercept is 0
#p value for that is 2e-16 so reject

#2.d
#estimate for sigma^2 is ('residual standard error')^2
sigma_hat_sq=fit1.su$'Residual standard error'
sigma_hat_sq=summary(fit1)$'Residual standard error'
sigma_hat_sq
#read out from table
#take the square of that

#2.e comment on the total variation explained by the modell
summary(fit1)
#we see that r^2 = 0.8182 hence 81% of the data are explained by our modell

#2.f is the modell useful to predict salaries, 5% sig level
anova(fit1)
# he uses a different value for the F value, so dont know whats going on but our F value is small (2.2e-16 ) so the modell is useful to predict sallaries. he also said that the F stat shows whether our model is better with the slope parameter or without
#sometimes he uses the value from the table, sometimes a different value
 
#2.g predict a salary for 20 years, with a 95% prediction interval 
newexp = data.frame(year=20)
exper20=predict(fit1,newdata=newexp, interval = 'prediction') ; exper20
#so the predicted salary is 51 with a 95% prediction interval (34.6,67.57)

#2.h
#if the regression modell is correct, the variance of the residuals should not depend on the values of the predictor
#i. plot the residuals vs fitted values
plot(fitted(fit1), residuals(fit1))
plot(salary$year^2, residuals(fit1))
# if the variance grows than we have a wrong modell
#variance of residuals depends on the predictor variables meaning for different xi we have a different region of variance. this  a contradiction, modell is shite
savehistory('lab4.txt')
